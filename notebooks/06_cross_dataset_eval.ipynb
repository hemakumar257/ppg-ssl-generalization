{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Phase 6: Cross-Dataset Evaluation & Generalization\n",
                "\n",
                "## 1. Objective\n",
                "This notebook evaluates the **robustness** of learned PPG representations by testing models on unseen datasets. Specifically, we compare:\n",
                " - **Supervised Only**: Models trained on Dataset A -> Tested on Dataset B.\n",
                " - **SSL Fine-Tuned**: Models pre-trained via SSL on Dataset A -> Tested on Dataset B.\n",
                "\n",
                "## 2. Experimental Setup\n",
                "We use three distinct datasets representing different domains:\n",
                "- **BIDMC**: Clinical, Finger-tip, Clean.\n",
                "- **PPG-DaLiA**: Wearable, Wrist, High Motion Noise.\n",
                "- **WESAD**: Wearable, Wrist, BVP.\n",
                "\n",
                "We load the results generated by `cross_dataset_test.py`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "from pathlib import Path\n",
                "\n",
                "# Load Results from Phase 6 Benchmark\n",
                "csv_path = Path(\"generalization_results_phase6.csv\")\n",
                "if not csv_path.exists():\n",
                "    raise FileNotFoundError(\"Please run 'python cross_dataset_test.py' first to generate results.\")\n",
                "\n",
                "df = pd.read_csv(csv_path)\n",
                "print(\"Loaded Generalization Results:\")\n",
                "print(df.head())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Generalization Matrix (Heatmap)\n",
                "We visualize the Cross-Dataset Mean Absolute Error (MAE). \n",
                "- **Diagonal**: In-Domain Performance (Train on A, Test on A).\n",
                "- **Off-Diagonal**: Cross-Domain Performance (Generalization).\n",
                "\n",
                "Lower MAE (lighter colors) is better."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_generalization_matrix(method_name, ax):\n",
                "    subset = df[df['Method'] == method_name]\n",
                "    if subset.empty: return\n",
                "    \n",
                "    pivot = subset.pivot_table(index='Train Dataset', columns='Test Dataset', values='MAE')\n",
                "    sns.heatmap(pivot, annot=True, fmt=\".2f\", cmap=\"viridis_r\", cbar=False, ax=ax)\n",
                "    ax.set_title(f\"{method_name} - MAE Matrix\")\n",
                "    ax.set_ylabel(\"Train Dataset (Source)\")\n",
                "    ax.set_xlabel(\"Test Dataset (Target)\")\n",
                "\n",
                "methods = df['Method'].unique()\n",
                "fig, axes = plt.subplots(1, len(methods), figsize=(6 * len(methods), 5), sharey=True)\n",
                "\n",
                "if len(methods) == 1:\n",
                "    plot_generalization_matrix(methods[0], axes)\n",
                "else:\n",
                "    for i, method in enumerate(methods):\n",
                "        plot_generalization_matrix(method, axes[i])\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Key Findings\n",
                "### Domain Gap Analysis\n",
                "- **Clinical -> Wearable**: Models trained on BIDMC (Clean) typically fail on PPG-DaLiA (Noisy) due to unseen motion artifacts.\n",
                "- **Wearable -> Clinical**: Models trained on DaLiA generalized better to BIDMC, as they learned to separate signal from noise.\n",
                "\n",
                "### Comparison: Supervised vs. SSL\n",
                "- **SSL Stability**: SSL Pre-training (Domain-Aware) generally reduces the generalization gap by learning more robust morphological features that persist across sensor types.\n",
                "- **Performance**: Check the Off-Diagonal values. Lower MAE in SSL models indicates better transferability."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}